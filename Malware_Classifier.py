'''
Import Util
'''
#Import preprocessing
from os import P_DETACH
import os
import pandas as pd
import numpy as np
from sklearn import preprocessing

#Import MinMax scaler
from sklearn.preprocessing import MinMaxScaler

#Import train / test split
from sklearn.model_selection import train_test_split

#Import Multiprocessing
import multiprocessing

#Warning Message off
import warnings
warnings.filterwarnings(action='ignore')

#Saving models
import joblib

'''
Import Models
'''
#Import xgboost
import xgboost as xgb
from xgboost.training import cv, train

#Import GBM
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV

#Import LGBM - need installation
from lightgbm import LGBMClassifier

#Import Adaboost
from sklearn.ensemble import AdaBoostClassifier

#Import Catboost
from catboost import CatBoostClassifier

#Import Metrics
from sklearn.metrics import mean_squared_error
from sklearn.metrics import explained_variance_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

class Model:

    def __init__(self):
        '''
        Making Model
        '''
        x,y = Model.Get_Csv('./pe_features.csv')
        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)

        #Completed models
        Model.Xgboost(x, y, x_train, x_test, y_train, y_test)
        Model.Adaboost(x, y, x_train, x_test, y_train, y_test)
        Model.GBM(x, y, x_train, x_test, y_train, y_test)
        Model.LGBM(x, y, x_train, x_test, y_train, y_test)
        Model.Catboost(x, y, x_train, x_test, y_train, y_test)

    def Xgboost(x, y, x_train, x_test, y_train, y_test):
        '''
        xgboost Implementation
        '''
        xgb_model = xgb.XGBClassifier(base_score=0.5, max_delta_step=0, min_child_weight=1, n_jobs=3, objective='binary:logistic', random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, booster='gbtree', n_estimators = 500, learning_rate=0.001, gamma=0, subsample=0.75, colsample_bytree=1, max_depth = 10)
        xgb_model = xgb_model.fit(x_train, y_train)

        Model.predictions('XGBoost',xgb_model, x_test, y_test)

        #Model Saving
        joblib.dump(xgb_model, open('./xgb_model.model', 'wb'))

    def Adaboost(x, y, x_train, x_test, y_train, y_test):
        '''
        adaboost Implementation
        '''
        ada = AdaBoostClassifier(n_estimators=1000, learning_rate=0.08, random_state=0)
        ada = ada.fit(x_train, y_train)
        Model.predictions('ADABoost',ada, x_test, y_test)

        #Model Saving
        joblib.dump(ada, open('./ada_model.model', 'wb'))
        
    def GBM(x, y, x_train, x_test, y_train, y_test):
        '''
        gbm Implementation
        '''
        gbm = GradientBoostingClassifier(random_state=0)
        #Model.Find_Gbm_Hyperparameter(gbm, x_train, y_train)

        gbm.fit(x_train, y_train)
        Model.predictions('GBM',gbm, x_test, y_test)
        
        #Model Saving
        joblib.dump(gbm, open('./gbm_model.model', 'wb'))
    
    def Find_Gbm_Hyperparameter(gbm, x_train, y_train):
        '''
        get gbm hyperparameter automatically
        '''
        print("[+] Find Best GBM Hyperparameter")
        params = {
            'n_estimators':[1000],
            'learning_rate':[0.1]
        }
        grid_cv = GridSearchCV(gbm, param_grid=params, cv = 2, verbose=1, n_jobs=multiprocessing.cpu_count() - 1)
        grid_cv.fit(x_train, y_train)
        print('Best fitting Hyperparameter : {}'.format(grid_cv.best_params_))
        print('Best fitting Score : {0:.4f}'.format(grid_cv.best_score_))
        print("[-] Found Best GBM Hyperparameter")

    def LGBM(x, y, x_train, x_test, y_train, y_test):
        lgbm = LGBMClassifier(n_estimators=820, learning_rate=0.1)
        evals = [(x_test, y_test)]
        lgbm.fit(x_train, y_train, eval_metric="logloss", eval_set=evals, verbose=False)
        Model.predictions('LGBM',lgbm, x_test, y_test)

        #Model Saving
        joblib.dump(lgbm, open('./lgbm_model.model', 'wb'))

    def Catboost(x, y, x_train, x_test, y_train, y_test):
        cbc = CatBoostClassifier(n_estimators=820, verbose=False)
        cbc.fit(x_train, y_train)
        Model.predictions('Catboost', cbc, x_test, y_test)

        #Model Saving
        joblib.dump(cbc, open('./cbc_model.model', 'wb'))

    def predictions(model_name, model, x_test, y_test):
        preds = model.predict(x_test)
        
        print("{} accuracy : \n".format(model_name))
        print(classification_report(y_test, preds, digits=4) )

    def Get_Csv(filename):
        '''
        get Dataset from csv
        '''
        #Get x, y from csv file
        csv_file = pd.read_csv(filename)
        x, y = csv_file.iloc[:, :-1],csv_file.iloc[:,-1]
        
        #Drop specific columns
        #x = Model.Change_Types(Model.Check_Drop(x))
        x = Model.Change_Types(Model.Check_Drop(x))
        
        #Describe Data
        #Model.Check_Describe(x)
        #Model.Check_Describe(y)
        return x, y
    
    def Check_Drop(x):
        '''
        Manipulate columns for accuracy
        '''
        x = x.drop('filename', axis=1)
        '''
        x = x.drop('e_magic', axis=1)
        x = x.drop('e_minalloc', axis=1)
        x = x.drop('e_ovno', axis=1)
        x = x.drop('Signature', axis=1)
        x = x.drop('AddressOfEntryPoint', axis=1)
        x = x.drop('EntryPoint', axis=1)
        x = x.drop('SectionAlignment', axis=1)
        x = x.drop('SizeOfImage', axis=1)
        x = x.drop('SizeOfHeaders', axis=1)
        x = x.drop('NumberOfRvaAndSizes', axis=1)
        x = x.drop('.textSectionName', axis=1)
        x = x.drop('.textSectionVirtualSize', axis=1)
        x = x.drop('.textSection|VirtualSize-SizeOfRawData|', axis=1)
        x = x.drop('raw_rich_header', axis=1)
        x = x.drop('.relocSectionName', axis=1)
        x = x.drop('.rdataSectionName', axis=1)
        x = x.drop('SizeOfUninitializedData', axis=1)
        x = x.drop('.dataSectionName', axis=1)
        x = x.drop('.dataSectionVirtualSize', axis=1)
        x = x.drop('.dataSection|VirtualSize-SizeOfRawData|', axis=1)
        x = x.drop('.dataSectionVirtualAddress', axis=1)
        x = x.drop('.dataSectionSizeOfRawData', axis=1)
        x = x.drop('.dataSectionPointerToRawData', axis=1)
        x = x.drop('.dataSectionCharacteristics', axis=1)
        #x = x.drop('.dataSectionEntropy', axis=1)
        '''
        return x

    def Change_Types(x):
        '''
        Changing Types
        '''
        lbl = preprocessing.LabelEncoder()
        #x['filename'] = lbl.fit_transform(x['filename'].astype(str))
        x['.textSectionName'] = lbl.fit_transform(x['.textSectionName'].astype(str))
        x['.textSectionVirtualSize'] = lbl.fit_transform(x['.textSectionVirtualSize'].astype(str))
        x['.textSection|VirtualSize-SizeOfRawData|'] = lbl.fit_transform(x['.textSection|VirtualSize-SizeOfRawData|'].astype(str))
        x['raw_rich_header'] = lbl.fit_transform(x['raw_rich_header'].astype(str))
        x['.dataSectionName'] = lbl.fit_transform(x['.dataSectionName'].astype(str))
        x['.dataSectionVirtualSize'] = lbl.fit_transform(x['.dataSectionVirtualSize'].astype(str))
        x['.dataSection|VirtualSize-SizeOfRawData|'] = lbl.fit_transform(x['.dataSection|VirtualSize-SizeOfRawData|'].astype(str))
        x['.dataSectionVirtualAddress'] = lbl.fit_transform(x['.dataSectionVirtualAddress'].astype(str))
        x['.dataSectionSizeOfRawData'] = lbl.fit_transform(x['.dataSectionSizeOfRawData'].astype(str))
        x['.dataSectionPointerToRawData'] = lbl.fit_transform(x['.dataSectionPointerToRawData'].astype(str))
        x['.dataSectionCharacteristics'] = lbl.fit_transform(x['.dataSectionCharacteristics'].astype(str))
        x['.dataSectionEntropy'] = lbl.fit_transform(x['.dataSectionEntropy'].astype(str))
        x['.rdataSectionName'] = lbl.fit_transform(x['.rdataSectionName'].astype(str))
        x['.relocSectionName'] = lbl.fit_transform(x['.relocSectionName'].astype(str))
        x['.textSectionVirtualAddress'] = lbl.fit_transform(x['.textSectionVirtualAddress'].astype(str))
        x['.textSectionSizeOfRawData'] = lbl.fit_transform(x['.textSectionSizeOfRawData'].astype(str))
        x['.textSectionPointerToRawData'] = lbl.fit_transform(x['.textSectionPointerToRawData'].astype(str))
        x['.textSectionCharacteristics'] = lbl.fit_transform(x['.textSectionCharacteristics'].astype(str))
        x['.textSectionEntropy'] = lbl.fit_transform(x['.textSectionEntropy'].astype(str))
        x['.rsrcSectionName'] = lbl.fit_transform(x['.rsrcSectionName'].astype(str))
        x['.rsrcSectionVirtualSize'] = lbl.fit_transform(x['.rsrcSectionVirtualSize'].astype(str))
        x['.rsrcSection|VirtualSize-SizeOfRawData|'] = lbl.fit_transform(x['.rsrcSection|VirtualSize-SizeOfRawData|'].astype(str))
        x['.rsrcSectionVirtualAddress'] = lbl.fit_transform(x['.rsrcSectionVirtualAddress'].astype(str))
        x['.rsrcSectionSizeOfRawData'] = lbl.fit_transform(x['.rsrcSectionSizeOfRawData'].astype(str))
        x['.rsrcSectionPointerToRawData'] = lbl.fit_transform(x['.rsrcSectionPointerToRawData'].astype(str))
        x['.rsrcSectionCharacteristics'] = lbl.fit_transform(x['.rsrcSectionCharacteristics'].astype(str))
        x['.rsrcSectionEntropy'] = lbl.fit_transform(x['.rsrcSectionEntropy'].astype(str))
        x['.rdataSectionVirtualSize'] = lbl.fit_transform(x['.rdataSectionVirtualSize'].astype(str))
        x['.rdataSection|VirtualSize-SizeOfRawData|'] = lbl.fit_transform(x['.rdataSection|VirtualSize-SizeOfRawData|'].astype(str))
        x['.rdataSectionVirtualAddress'] = lbl.fit_transform(x['.rdataSectionVirtualAddress'].astype(str))
        x['.rdataSectionSizeOfRawData'] = lbl.fit_transform(x['.rdataSectionSizeOfRawData'].astype(str))
        x['.rdataSectionPointerToRawData'] = lbl.fit_transform(x['.rdataSectionPointerToRawData'].astype(str))
        x['.rdataSectionCharacteristics'] = lbl.fit_transform(x['.rdataSectionCharacteristics'].astype(str))
        x['.rdataSectionEntropy'] = lbl.fit_transform(x['.rdataSectionEntropy'].astype(str))
        x['.relocSectionVirtualSize'] = lbl.fit_transform(x['.relocSectionVirtualSize'].astype(str))
        x['.relocSection|VirtualSize-SizeOfRawData|'] = lbl.fit_transform(x['.relocSection|VirtualSize-SizeOfRawData|'].astype(str))
        x['.relocSectionVirtualAddress'] = lbl.fit_transform(x['.relocSectionVirtualAddress'].astype(str))
        x['.relocSectionSizeOfRawData'] = lbl.fit_transform(x['.relocSectionSizeOfRawData'].astype(str))
        x['.relocSectionPointerToRawData'] = lbl.fit_transform(x['.relocSectionPointerToRawData'].astype(str))
        x['.relocSectionCharacteristics'] = lbl.fit_transform(x['.relocSectionCharacteristics'].astype(str))
        x['.relocSectionEntropy'] = lbl.fit_transform(x['.relocSectionEntropy'].astype(str))
        
        x = pd.DataFrame(MinMaxScaler().fit_transform(x))
        return x

    def Check_Describe(x):
        '''
        Describe Dataset
        '''
        print("--------------Data--------------")
        print('{}'.format(x))
        print("--------------------------------")
        print("------------Describe------------")
        print('{}'.format(x.describe()))
        print("--------------------------------")
        print("-------------Dtypes-------------")
        print('{}'.format(x.dtypes))
        print("--------------------------------")

class Model_Validation:

    def __init__(self):
        x_test, y_test = Model.Get_Csv('./validation_features.csv')
        
        Model_Validation.Check_Xgboost(x_test, y_test)
        Model_Validation.Check_Adaboost(x_test, y_test)
        Model_Validation.Check_Gbmoost(x_test, y_test)
        Model_Validation.Check_Lgboost(x_test, y_test)
        Model_Validation.Check_Catboost(x_test, y_test)

    def Check_Xgboost(x_test, y_test):
        xgb = joblib.load(open('./xgb_model.model', 'rb'))
        Model.predictions('XGBoost  Validation',xgb, x_test, y_test)

    def Check_Adaboost(x_test, y_test):
        ada = joblib.load(open('./ada_model.model', 'rb'))
        Model.predictions('Adaoost  Validation',ada, x_test, y_test)

    def Check_Gbmoost(x_test, y_test):
        gbm = joblib.load(open('./gbm_model.model', 'rb'))
        Model.predictions('GBM  Validation',gbm, x_test, y_test)

    def Check_Lgboost(x_test, y_test):
        lgbm = joblib.load(open('./lgbm_model_88.model', 'rb'))
        Model.predictions('LGBM  Validation',lgbm, x_test, y_test)

    def Check_Catboost(x_test, y_test):
        cbc = joblib.load(open('./cbc_model_87.model', 'rb'))
        Model.predictions('Catboost Validation',cbc, x_test, y_test)

if __name__ == "__main__":
    #Create Training Model
    #Model()

    #Check Validation
    Model_Validation()
